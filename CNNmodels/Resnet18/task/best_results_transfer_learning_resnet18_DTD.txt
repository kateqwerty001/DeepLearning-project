# final

learning_rate =  0.001
Training - Epoch 1/100, Loss: 4.0063, Accuracy: 25.0000%
Testing - Epoch 1/100, Loss: 2.5740, Accuracy: 37.5000%
Time: 15.40 seconds
learning_rate =  0.001
Training - Epoch 2/100, Loss: 1.8826, Accuracy: 45.9375%
Testing - Epoch 2/100, Loss: 1.3514, Accuracy: 56.7857%
Time: 34.41 seconds
learning_rate =  0.001
Training - Epoch 3/100, Loss: 1.2496, Accuracy: 59.4643%
Testing - Epoch 3/100, Loss: 0.9741, Accuracy: 69.2857%
Time: 53.76 seconds
learning_rate =  0.001
Training - Epoch 4/100, Loss: 0.9846, Accuracy: 66.6964%
Testing - Epoch 4/100, Loss: 0.8069, Accuracy: 72.6786%
Time: 72.96 seconds
learning_rate =  0.001
Training - Epoch 5/100, Loss: 0.8445, Accuracy: 70.3125%
Testing - Epoch 5/100, Loss: 0.7037, Accuracy: 73.3929%
Time: 91.70 seconds
learning_rate =  0.001
Training - Epoch 6/100, Loss: 0.7639, Accuracy: 72.6339%
Testing - Epoch 6/100, Loss: 0.6559, Accuracy: 76.2500%
Time: 111.07 seconds
learning_rate =  0.001
Training - Epoch 7/100, Loss: 0.7090, Accuracy: 74.9554%
Testing - Epoch 7/100, Loss: 0.6073, Accuracy: 77.1429%
Time: 130.18 seconds
learning_rate =  0.001
Training - Epoch 8/100, Loss: 0.6539, Accuracy: 76.4732%
Testing - Epoch 8/100, Loss: 0.5936, Accuracy: 78.3929%
Time: 149.09 seconds
learning_rate =  0.001
Training - Epoch 9/100, Loss: 0.6410, Accuracy: 77.1875%
Testing - Epoch 9/100, Loss: 0.5712, Accuracy: 79.2857%
Time: 168.48 seconds
learning_rate =  0.001
Training - Epoch 10/100, Loss: 0.6032, Accuracy: 78.1696%
Testing - Epoch 10/100, Loss: 0.5415, Accuracy: 80.5357%
Time: 188.04 seconds
learning_rate =  0.001
Training - Epoch 11/100, Loss: 0.6029, Accuracy: 78.1250%
Testing - Epoch 11/100, Loss: 0.5386, Accuracy: 79.6429%
Time: 206.94 seconds
learning_rate =  0.001
Training - Epoch 12/100, Loss: 0.5748, Accuracy: 78.9732%
Testing - Epoch 12/100, Loss: 0.5194, Accuracy: 80.8929%
Time: 226.20 seconds
learning_rate =  0.001
Training - Epoch 13/100, Loss: 0.5539, Accuracy: 80.0893%
Testing - Epoch 13/100, Loss: 0.5107, Accuracy: 82.1429%
Time: 245.71 seconds
learning_rate =  0.001
Training - Epoch 14/100, Loss: 0.5242, Accuracy: 81.1161%
Testing - Epoch 14/100, Loss: 0.5045, Accuracy: 81.4286%
Time: 264.55 seconds
learning_rate =  0.001
Training - Epoch 15/100, Loss: 0.5202, Accuracy: 81.0714%
Testing - Epoch 15/100, Loss: 0.4878, Accuracy: 82.8571%
Time: 283.60 seconds
learning_rate =  0.001
Training - Epoch 16/100, Loss: 0.5128, Accuracy: 80.6250%
Testing - Epoch 16/100, Loss: 0.4841, Accuracy: 83.0357%
Time: 302.87 seconds
learning_rate =  0.001
Training - Epoch 17/100, Loss: 0.5123, Accuracy: 80.5357%
Testing - Epoch 17/100, Loss: 0.4903, Accuracy: 83.2143%
Time: 322.07 seconds
learning_rate =  0.001
Training - Epoch 18/100, Loss: 0.4818, Accuracy: 82.7232%
Testing - Epoch 18/100, Loss: 0.4694, Accuracy: 83.0357%
Time: 340.86 seconds
learning_rate =  0.001
Training - Epoch 19/100, Loss: 0.4930, Accuracy: 81.7857%
Testing - Epoch 19/100, Loss: 0.4653, Accuracy: 83.2143%
Time: 360.40 seconds
learning_rate =  0.001
Training - Epoch 20/100, Loss: 0.4738, Accuracy: 82.8571%
Testing - Epoch 20/100, Loss: 0.4665, Accuracy: 82.3214%
Time: 379.92 seconds
learning_rate =  0.001
Training - Epoch 21/100, Loss: 0.4814, Accuracy: 82.5000%
Testing - Epoch 21/100, Loss: 0.4693, Accuracy: 83.2143%
Time: 398.61 seconds
learning_rate =  0.001
Training - Epoch 22/100, Loss: 0.4622, Accuracy: 83.0357%
Testing - Epoch 22/100, Loss: 0.4583, Accuracy: 82.8571%
Time: 418.09 seconds
learning_rate =  0.001
Training - Epoch 23/100, Loss: 0.4526, Accuracy: 83.2589%
Testing - Epoch 23/100, Loss: 0.4652, Accuracy: 83.7500%
Time: 436.94 seconds
learning_rate =  0.001
Training - Epoch 24/100, Loss: 0.4484, Accuracy: 83.6161%
Testing - Epoch 24/100, Loss: 0.4575, Accuracy: 82.8571%
Time: 456.02 seconds
learning_rate =  0.001
Training - Epoch 25/100, Loss: 0.4407, Accuracy: 83.4375%
Testing - Epoch 25/100, Loss: 0.4387, Accuracy: 84.2857%
Time: 475.44 seconds
learning_rate =  0.001
Training - Epoch 26/100, Loss: 0.4276, Accuracy: 84.4643%
Testing - Epoch 26/100, Loss: 0.4371, Accuracy: 83.7500%
Time: 494.30 seconds
learning_rate =  0.001
Training - Epoch 27/100, Loss: 0.4410, Accuracy: 83.3482%
Testing - Epoch 27/100, Loss: 0.4335, Accuracy: 83.7500%
Time: 513.15 seconds
learning_rate =  0.001
Training - Epoch 28/100, Loss: 0.4249, Accuracy: 84.0625%
Testing - Epoch 28/100, Loss: 0.4283, Accuracy: 84.2857%
Time: 532.53 seconds
learning_rate =  0.001
Training - Epoch 29/100, Loss: 0.4113, Accuracy: 84.9554%
Testing - Epoch 29/100, Loss: 0.4261, Accuracy: 83.9286%
Time: 551.48 seconds
learning_rate =  0.001
Training - Epoch 30/100, Loss: 0.4291, Accuracy: 84.5536%
Testing - Epoch 30/100, Loss: 0.4304, Accuracy: 83.0357%
Time: 570.39 seconds
learning_rate =  0.001
Training - Epoch 31/100, Loss: 0.4182, Accuracy: 84.2857%
Testing - Epoch 31/100, Loss: 0.4255, Accuracy: 84.8214%
Time: 589.46 seconds
learning_rate =  0.0001
Training - Epoch 32/100, Loss: 0.4143, Accuracy: 85.0893%
Testing - Epoch 32/100, Loss: 0.4198, Accuracy: 83.9286%
Time: 608.66 seconds
learning_rate =  0.0001
Training - Epoch 33/100, Loss: 0.3946, Accuracy: 85.8929%
Testing - Epoch 33/100, Loss: 0.4226, Accuracy: 84.6429%
Time: 627.92 seconds
learning_rate =  0.0001
Training - Epoch 34/100, Loss: 0.4084, Accuracy: 84.5536%
Testing - Epoch 34/100, Loss: 0.4120, Accuracy: 84.1071%
Time: 647.32 seconds
learning_rate =  0.0001
Training - Epoch 35/100, Loss: 0.4043, Accuracy: 85.2679%
Testing - Epoch 35/100, Loss: 0.4143, Accuracy: 83.9286%
Time: 666.49 seconds
learning_rate =  0.0001
Training - Epoch 36/100, Loss: 0.4027, Accuracy: 85.1339%
Testing - Epoch 36/100, Loss: 0.4125, Accuracy: 83.9286%
Time: 685.44 seconds
learning_rate =  0.0001
Training - Epoch 37/100, Loss: 0.4100, Accuracy: 85.0000%
Testing - Epoch 37/100, Loss: 0.4109, Accuracy: 85.5357%
Time: 704.47 seconds
learning_rate =  0.0001
Training - Epoch 38/100, Loss: 0.3996, Accuracy: 85.5357%
Testing - Epoch 38/100, Loss: 0.4196, Accuracy: 85.3571%
Time: 723.67 seconds
learning_rate =  0.0001
Training - Epoch 39/100, Loss: 0.3712, Accuracy: 86.9196%
Testing - Epoch 39/100, Loss: 0.3893, Accuracy: 85.5357%
Time: 742.62 seconds
learning_rate =  0.0001
Training - Epoch 40/100, Loss: 0.3705, Accuracy: 86.6964%
Testing - Epoch 40/100, Loss: 0.4182, Accuracy: 83.2143%
Time: 761.67 seconds
learning_rate =  0.0001
Training - Epoch 41/100, Loss: 0.3720, Accuracy: 86.7857%
Testing - Epoch 41/100, Loss: 0.4012, Accuracy: 85.3571%
Time: 780.92 seconds
learning_rate =  0.0001
Training - Epoch 42/100, Loss: 0.3958, Accuracy: 85.8036%
Testing - Epoch 42/100, Loss: 0.4164, Accuracy: 84.4643%
Time: 800.00 seconds
learning_rate =  0.0001
Training - Epoch 43/100, Loss: 0.3777, Accuracy: 86.6964%
Testing - Epoch 43/100, Loss: 0.3870, Accuracy: 86.2500%
Time: 819.00 seconds
learning_rate =  0.0001
Training - Epoch 44/100, Loss: 0.3701, Accuracy: 86.3839%
Testing - Epoch 44/100, Loss: 0.4012, Accuracy: 83.9286%
Time: 838.27 seconds
learning_rate =  0.0001
Training - Epoch 45/100, Loss: 0.3876, Accuracy: 86.2500%
Testing - Epoch 45/100, Loss: 0.4116, Accuracy: 85.3571%
Time: 857.36 seconds
learning_rate =  0.0001
Training - Epoch 46/100, Loss: 0.3823, Accuracy: 85.8036%
Testing - Epoch 46/100, Loss: 0.3905, Accuracy: 86.2500%
Time: 876.01 seconds
learning_rate =  0.0001
Training - Epoch 47/100, Loss: 0.3721, Accuracy: 86.0268%
Testing - Epoch 47/100, Loss: 0.4140, Accuracy: 84.4643%
Time: 895.51 seconds
learning_rate =  0.0001
Training - Epoch 48/100, Loss: 0.3536, Accuracy: 87.2321%
Testing - Epoch 48/100, Loss: 0.4060, Accuracy: 84.2857%
Time: 914.51 seconds
learning_rate =  0.0001
Training - Epoch 49/100, Loss: 0.3694, Accuracy: 86.2946%
Testing - Epoch 49/100, Loss: 0.4089, Accuracy: 84.4643%
Time: 933.46 seconds
learning_rate =  0.0001
Training - Epoch 50/100, Loss: 0.3733, Accuracy: 86.4286%
Testing - Epoch 50/100, Loss: 0.3855, Accuracy: 85.8929%
Time: 952.81 seconds
learning_rate =  0.0001
Training - Epoch 51/100, Loss: 0.3485, Accuracy: 87.2321%
Testing - Epoch 51/100, Loss: 0.3955, Accuracy: 84.8214%
Time: 971.71 seconds
learning_rate =  0.0001
Training - Epoch 52/100, Loss: 0.3619, Accuracy: 87.0536%
Testing - Epoch 52/100, Loss: 0.3886, Accuracy: 85.1786%
Time: 990.67 seconds
learning_rate =  0.0001
Training - Epoch 53/100, Loss: 0.3640, Accuracy: 87.4107%
Testing - Epoch 53/100, Loss: 0.4204, Accuracy: 84.6429%
Time: 1010.09 seconds
learning_rate =  0.0001
Training - Epoch 54/100, Loss: 0.3558, Accuracy: 87.1875%
Testing - Epoch 54/100, Loss: 0.3874, Accuracy: 85.7143%
Time: 1029.09 seconds
learning_rate =  0.0001
Training - Epoch 55/100, Loss: 0.3541, Accuracy: 87.0089%
Testing - Epoch 55/100, Loss: 0.3882, Accuracy: 85.7143%
Time: 1048.46 seconds
learning_rate =  0.0001
Training - Epoch 56/100, Loss: 0.3595, Accuracy: 86.2946%
Testing - Epoch 56/100, Loss: 0.3888, Accuracy: 85.7143%
Time: 1067.47 seconds
learning_rate =  0.0001
Training - Epoch 57/100, Loss: 0.3307, Accuracy: 87.9464%
Testing - Epoch 57/100, Loss: 0.4133, Accuracy: 84.2857%
Time: 1086.84 seconds
learning_rate =  0.0001
Training - Epoch 58/100, Loss: 0.3400, Accuracy: 87.8125%
Testing - Epoch 58/100, Loss: 0.3848, Accuracy: 85.8929%
Time: 1106.29 seconds
learning_rate =  0.0001
Training - Epoch 59/100, Loss: 0.3334, Accuracy: 87.7679%
Testing - Epoch 59/100, Loss: 0.3883, Accuracy: 85.3571%
Time: 1125.89 seconds
learning_rate =  0.0001
Training - Epoch 60/100, Loss: 0.3256, Accuracy: 88.6607%
Testing - Epoch 60/100, Loss: 0.3756, Accuracy: 85.5357%
Time: 1145.52 seconds
learning_rate =  0.0001
Training - Epoch 61/100, Loss: 0.3327, Accuracy: 88.3036%
Testing - Epoch 61/100, Loss: 0.4053, Accuracy: 84.6429%
Time: 1164.77 seconds
learning_rate =  0.0001
Training - Epoch 62/100, Loss: 0.3383, Accuracy: 87.5000%
Testing - Epoch 62/100, Loss: 0.3926, Accuracy: 84.8214%
Time: 1183.92 seconds
learning_rate =  0.0001
Training - Epoch 63/100, Loss: 0.3447, Accuracy: 87.4554%
Testing - Epoch 63/100, Loss: 0.3792, Accuracy: 86.0714%
Time: 1203.41 seconds
learning_rate =  0.0001
Training - Epoch 64/100, Loss: 0.3225, Accuracy: 88.4375%
Testing - Epoch 64/100, Loss: 0.3796, Accuracy: 85.5357%
Time: 1222.14 seconds
learning_rate =  0.0001
Training - Epoch 65/100, Loss: 0.3358, Accuracy: 88.3036%
Testing - Epoch 65/100, Loss: 0.4035, Accuracy: 84.2857%
Time: 1241.21 seconds
learning_rate =  0.0001
Training - Epoch 66/100, Loss: 0.3557, Accuracy: 87.0536%
Testing - Epoch 66/100, Loss: 0.3935, Accuracy: 85.0000%
Time: 1260.70 seconds
learning_rate =  0.0001
Training - Epoch 67/100, Loss: 0.3190, Accuracy: 88.6607%
Testing - Epoch 67/100, Loss: 0.3984, Accuracy: 84.1071%
Time: 1279.77 seconds
learning_rate =  0.0001
Training - Epoch 68/100, Loss: 0.3384, Accuracy: 87.9464%
Testing - Epoch 68/100, Loss: 0.3937, Accuracy: 86.2500%
Time: 1298.68 seconds
learning_rate =  0.0001
Training - Epoch 69/100, Loss: 0.3305, Accuracy: 87.8125%
Testing - Epoch 69/100, Loss: 0.4126, Accuracy: 85.3571%
Time: 1318.02 seconds
learning_rate =  0.0001
Training - Epoch 70/100, Loss: 0.3232, Accuracy: 88.1696%
Testing - Epoch 70/100, Loss: 0.4160, Accuracy: 85.3571%
Time: 1337.06 seconds
learning_rate =  0.0001
Training - Epoch 71/100, Loss: 0.3318, Accuracy: 87.9464%
Testing - Epoch 71/100, Loss: 0.3804, Accuracy: 85.3571%
Time: 1355.98 seconds
learning_rate =  0.0001
Training - Epoch 72/100, Loss: 0.3056, Accuracy: 89.5982%
Testing - Epoch 72/100, Loss: 0.4020, Accuracy: 85.3571%
Time: 1375.10 seconds
learning_rate =  0.0001
Training - Epoch 73/100, Loss: 0.3158, Accuracy: 88.3482%
Testing - Epoch 73/100, Loss: 0.3760, Accuracy: 86.2500%
Time: 1394.02 seconds
learning_rate =  0.0001
Training - Epoch 74/100, Loss: 0.3267, Accuracy: 88.6161%
Testing - Epoch 74/100, Loss: 0.3851, Accuracy: 86.9643%
Time: 1413.02 seconds
learning_rate =  0.0001
Training - Epoch 75/100, Loss: 0.3108, Accuracy: 89.1071%
Testing - Epoch 75/100, Loss: 0.3883, Accuracy: 85.5357%
Time: 1432.18 seconds
learning_rate =  0.0001
Training - Epoch 76/100, Loss: 0.3240, Accuracy: 88.3482%
Testing - Epoch 76/100, Loss: 0.3812, Accuracy: 86.2500%
Time: 1451.29 seconds
learning_rate =  0.0001
Training - Epoch 77/100, Loss: 0.3179, Accuracy: 88.4821%
Testing - Epoch 77/100, Loss: 0.4092, Accuracy: 85.0000%
Time: 1470.21 seconds
learning_rate =  0.0001
Training - Epoch 78/100, Loss: 0.3317, Accuracy: 88.4821%
Testing - Epoch 78/100, Loss: 0.3872, Accuracy: 85.5357%
Time: 1489.61 seconds
learning_rate =  0.0001
Training - Epoch 79/100, Loss: 0.3014, Accuracy: 89.0179%
Testing - Epoch 79/100, Loss: 0.3994, Accuracy: 85.7143%
Time: 1509.19 seconds
learning_rate =  0.0001
Training - Epoch 80/100, Loss: 0.3108, Accuracy: 89.1964%
Testing - Epoch 80/100, Loss: 0.4168, Accuracy: 85.1786%
Time: 1528.21 seconds
learning_rate =  0.0001
Training - Epoch 81/100, Loss: 0.3026, Accuracy: 88.8393%
Testing - Epoch 81/100, Loss: 0.3736, Accuracy: 86.0714%
Time: 1547.62 seconds
learning_rate =  0.0001
Training - Epoch 82/100, Loss: 0.3123, Accuracy: 88.7054%
Testing - Epoch 82/100, Loss: 0.3835, Accuracy: 85.8929%
Time: 1567.16 seconds
learning_rate =  0.0001
Training - Epoch 83/100, Loss: 0.3207, Accuracy: 88.5268%
Testing - Epoch 83/100, Loss: 0.3731, Accuracy: 87.1429%
Time: 1586.32 seconds
learning_rate =  0.0001
Training - Epoch 84/100, Loss: 0.2977, Accuracy: 89.5536%
Testing - Epoch 84/100, Loss: 0.3797, Accuracy: 85.5357%
Time: 1606.31 seconds
learning_rate =  0.0001
Training - Epoch 85/100, Loss: 0.3146, Accuracy: 88.3929%
Testing - Epoch 85/100, Loss: 0.3903, Accuracy: 84.6429%
Time: 1626.09 seconds
learning_rate =  0.0001
Training - Epoch 86/100, Loss: 0.2984, Accuracy: 88.9286%
Testing - Epoch 86/100, Loss: 0.3889, Accuracy: 84.2857%
Time: 1645.07 seconds
learning_rate =  0.0001
Training - Epoch 87/100, Loss: 0.3016, Accuracy: 89.1071%
Testing - Epoch 87/100, Loss: 0.3868, Accuracy: 86.2500%
Time: 1664.92 seconds
learning_rate =  0.0001
Training - Epoch 88/100, Loss: 0.3050, Accuracy: 89.2857%
Testing - Epoch 88/100, Loss: 0.3843, Accuracy: 85.5357%
Time: 1684.37 seconds
learning_rate =  0.0001
Training - Epoch 89/100, Loss: 0.3070, Accuracy: 88.9286%
Testing - Epoch 89/100, Loss: 0.3774, Accuracy: 86.0714%
Time: 1703.19 seconds
learning_rate =  0.0001
Training - Epoch 90/100, Loss: 0.2806, Accuracy: 90.0446%
Testing - Epoch 90/100, Loss: 0.3824, Accuracy: 86.2500%
Time: 1722.04 seconds
learning_rate =  0.0001
Training - Epoch 91/100, Loss: 0.2842, Accuracy: 89.9107%
Testing - Epoch 91/100, Loss: 0.4039, Accuracy: 86.2500%
Time: 1741.20 seconds
learning_rate =  0.0001
Training - Epoch 92/100, Loss: 0.3021, Accuracy: 89.3750%
Testing - Epoch 92/100, Loss: 0.3716, Accuracy: 86.4286%
Time: 1760.11 seconds
learning_rate =  0.0001
Training - Epoch 93/100, Loss: 0.2819, Accuracy: 90.1786%
Testing - Epoch 93/100, Loss: 0.3792, Accuracy: 87.1429%
Time: 1778.84 seconds
learning_rate =  0.0001
Training - Epoch 94/100, Loss: 0.2919, Accuracy: 90.0446%
Testing - Epoch 94/100, Loss: 0.3657, Accuracy: 86.4286%
Time: 1798.41 seconds
learning_rate =  0.0001
Training - Epoch 95/100, Loss: 0.2957, Accuracy: 89.6875%
Testing - Epoch 95/100, Loss: 0.3858, Accuracy: 86.4286%
Time: 1817.39 seconds
learning_rate =  0.0001
Training - Epoch 96/100, Loss: 0.2892, Accuracy: 90.2232%
Testing - Epoch 96/100, Loss: 0.3662, Accuracy: 86.0714%
Time: 1836.24 seconds
learning_rate =  0.0001
Training - Epoch 97/100, Loss: 0.2811, Accuracy: 89.9554%
Testing - Epoch 97/100, Loss: 0.3702, Accuracy: 86.4286%
Time: 1855.74 seconds
learning_rate =  0.0001
Training - Epoch 98/100, Loss: 0.2846, Accuracy: 89.7768%
Testing - Epoch 98/100, Loss: 0.3773, Accuracy: 86.0714%
Time: 1874.56 seconds
learning_rate =  0.0001
Training - Epoch 99/100, Loss: 0.2865, Accuracy: 90.0893%
Testing - Epoch 99/100, Loss: 0.3913, Accuracy: 85.8929%
Time: 1893.46 seconds
learning_rate =  0.0001
Training - Epoch 100/100, Loss: 0.2942, Accuracy: 89.6429%
Testing - Epoch 100/100, Loss: 0.3771, Accuracy: 85.8929%
Time: 1912.48 seconds
Training complete.
Training completed successfully.
Training accuracy:
[25.0, 45.9375, 59.464285714285715, 66.69642857142857, 70.3125, 72.63392857142857, 74.95535714285714, 76.47321428571429, 77.1875, 78.16964285714286, 78.125, 78.97321428571429, 80.08928571428572, 81.11607142857142, 81.07142857142857, 80.625, 80.53571428571429, 82.72321428571429, 81.78571428571428, 82.85714285714286, 82.5, 83.03571428571429, 83.25892857142857, 83.61607142857143, 83.4375, 84.46428571428571, 83.34821428571428, 84.0625, 84.95535714285715, 84.55357142857143, 84.28571428571429, 85.08928571428571, 85.89285714285714, 84.55357142857143, 85.26785714285714, 85.13392857142857, 85.0, 85.53571428571428, 86.91964285714285, 86.69642857142857, 86.78571428571429, 85.80357142857142, 86.69642857142857, 86.38392857142857, 86.25, 85.80357142857142, 86.02678571428571, 87.23214285714286, 86.29464285714286, 86.42857142857143, 87.23214285714286, 87.05357142857143, 87.41071428571429, 87.1875, 87.00892857142857, 86.29464285714286, 87.94642857142857, 87.8125, 87.76785714285714, 88.66071428571428, 88.30357142857143, 87.5, 87.45535714285714, 88.4375, 88.30357142857143, 87.05357142857143, 88.66071428571428, 87.94642857142857, 87.8125, 88.16964285714286, 87.94642857142857, 89.59821428571428, 88.34821428571429, 88.61607142857143, 89.10714285714286, 88.34821428571429, 88.48214285714285, 88.48214285714285, 89.01785714285714, 89.19642857142858, 88.83928571428571, 88.70535714285714, 88.52678571428572, 89.55357142857143, 88.39285714285714, 88.92857142857142, 89.10714285714286, 89.28571428571429, 88.92857142857142, 90.04464285714285, 89.91071428571429, 89.375, 90.17857142857143, 90.04464285714285, 89.6875, 90.22321428571428, 89.95535714285714, 89.77678571428571, 90.08928571428572, 89.64285714285715]
Test accuracy:
[37.5, 37.5, 56.785714285714285, 56.785714285714285, 69.28571428571428, 69.28571428571428, 72.67857142857143, 72.67857142857143, 73.39285714285714, 73.39285714285714, 76.25, 76.25, 77.14285714285715, 77.14285714285715, 78.39285714285714, 78.39285714285714, 79.28571428571428, 79.28571428571428, 80.53571428571429, 80.53571428571429, 79.64285714285714, 79.64285714285714, 80.89285714285714, 80.89285714285714, 82.14285714285714, 82.14285714285714, 81.42857142857143, 81.42857142857143, 82.85714285714286, 82.85714285714286, 83.03571428571429, 83.03571428571429, 83.21428571428572, 83.21428571428572, 83.03571428571429, 83.03571428571429, 83.21428571428572, 83.21428571428572, 82.32142857142857, 82.32142857142857, 83.21428571428572, 83.21428571428572, 82.85714285714286, 82.85714285714286, 83.75, 83.75, 82.85714285714286, 82.85714285714286, 84.28571428571429, 84.28571428571429, 83.75, 83.75, 83.75, 83.75, 84.28571428571429, 84.28571428571429, 83.92857142857143, 83.92857142857143, 83.03571428571429, 83.03571428571429, 84.82142857142857, 84.82142857142857, 83.92857142857143, 83.92857142857143, 84.64285714285714, 84.64285714285714, 84.10714285714286, 84.10714285714286, 83.92857142857143, 83.92857142857143, 83.92857142857143, 83.92857142857143, 85.53571428571428, 85.53571428571428, 85.35714285714285, 85.35714285714285, 85.53571428571428, 85.53571428571428, 83.21428571428572, 83.21428571428572, 85.35714285714285, 85.35714285714285, 84.46428571428571, 84.46428571428571, 86.25, 86.25, 83.92857142857143, 83.92857142857143, 85.35714285714285, 85.35714285714285, 86.25, 86.25, 84.46428571428571, 84.46428571428571, 84.28571428571429, 84.28571428571429, 84.46428571428571, 84.46428571428571, 85.89285714285714, 85.89285714285714, 84.82142857142857, 84.82142857142857, 85.17857142857143, 85.17857142857143, 84.64285714285714, 84.64285714285714, 85.71428571428571, 85.71428571428571, 85.71428571428571, 85.71428571428571, 85.71428571428571, 85.71428571428571, 84.28571428571429, 84.28571428571429, 85.89285714285714, 85.89285714285714, 85.35714285714285, 85.35714285714285, 85.53571428571428, 85.53571428571428, 84.64285714285714, 84.64285714285714, 84.82142857142857, 84.82142857142857, 86.07142857142858, 86.07142857142858, 85.53571428571428, 85.53571428571428, 84.28571428571429, 84.28571428571429, 85.0, 85.0, 84.10714285714286, 84.10714285714286, 86.25, 86.25, 85.35714285714285, 85.35714285714285, 85.35714285714285, 85.35714285714285, 85.35714285714285, 85.35714285714285, 85.35714285714285, 85.35714285714285, 86.25, 86.25, 86.96428571428572, 86.96428571428572, 85.53571428571428, 85.53571428571428, 86.25, 86.25, 85.0, 85.0, 85.53571428571428, 85.53571428571428, 85.71428571428571, 85.71428571428571, 85.17857142857143, 85.17857142857143, 86.07142857142858, 86.07142857142858, 85.89285714285714, 85.89285714285714, 87.14285714285714, 87.14285714285714, 85.53571428571428, 85.53571428571428, 84.64285714285714, 84.64285714285714, 84.28571428571429, 84.28571428571429, 86.25, 86.25, 85.53571428571428, 85.53571428571428, 86.07142857142858, 86.07142857142858, 86.25, 86.25, 86.25, 86.25, 86.42857142857143, 86.42857142857143, 87.14285714285714, 87.14285714285714, 86.42857142857143, 86.42857142857143, 86.42857142857143, 86.42857142857143, 86.07142857142858, 86.07142857142858, 86.42857142857143, 86.42857142857143, 86.07142857142858, 86.07142857142858, 85.89285714285714, 85.89285714285714, 85.89285714285714, 85.89285714285714]
Loss train:
[]
Test loss:
[2.573979994228908, 1.351437168461936, 0.9741342834063939, 0.8069474390574864, 0.7036530383995601, 0.6559136995247432, 0.6072717632566179, 0.5936364003590175, 0.5712318181991577, 0.5415443514074598, 0.538553933586393, 0.5193771157945906, 0.5107066895280565, 0.504520389863423, 0.4878369433539254, 0.48411273871149335, 0.4902575612068176, 0.46943198016711646, 0.465304000888552, 0.4665296690804618, 0.46933355842317853, 0.4582801222801208, 0.4651951594012124, 0.45753522259848456, 0.4386808327266148, 0.437127297265189, 0.4334505140781403, 0.42832043766975403, 0.42607011113848003, 0.4304220063345773, 0.4254649613584791, 0.41976970945085795, 0.42256311689104353, 0.411960540499006, 0.41425957594599044, 0.4125037831919534, 0.4109234775815691, 0.4195962795189449, 0.389305807862963, 0.4181616987500872, 0.40124871475355967, 0.4164439473833357, 0.38699332901409694, 0.40115234851837156, 0.4115922221115657, 0.39054687534059795, 0.4140030401093619, 0.40600613185337614, 0.40890969548906597, 0.38547184467315676, 0.39548480595861163, 0.3886158892086574, 0.42038865174566, 0.3874166148049491, 0.38817689759390694, 0.3888177761009761, 0.41330608810697284, 0.38483351469039917, 0.3883434082780566, 0.3755526287215097, 0.40534924013274054, 0.39256690314837867, 0.3791677245071956, 0.37961382951055256, 0.4035021134785243, 0.3934697219303676, 0.39842756475721086, 0.3937001594475337, 0.41256405540875024, 0.41604048098836627, 0.3804302385875157, 0.40203933545521325, 0.37603004915373667, 0.38513579879488263, 0.3883340963295528, 0.3812478252819606, 0.40923939432416645, 0.38724323340824673, 0.39941191162381856, 0.41675161719322207, 0.3735808891909463, 0.3834786747183119, 0.37312249030385697, 0.37966077498027256, 0.3902943321636745, 0.38888860855783736, 0.386796544279371, 0.38430648531232564, 0.3773679801395961, 0.3823938931737627, 0.4038998373917171, 0.3716480169977461, 0.3792089666639056, 0.3656816048281533, 0.38581879564693994, 0.36617903113365174, 0.3701541304588318, 0.37734115719795225, 0.3913414444242205, 0.3770911284855434]
Learning rate:
[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001]
Epoch times:
[15.404925107955933, 34.40924549102783, 53.759453773498535, 72.96272897720337, 91.70220804214478, 111.06903386116028, 130.18413519859314, 149.0941436290741, 168.47618103027344, 188.04042863845825, 206.9425013065338, 226.19997453689575, 245.70660138130188, 264.55406951904297, 283.604368686676, 302.8694179058075, 322.06678557395935, 340.86232113838196, 360.4008424282074, 379.9233572483063, 398.608446598053, 418.0915069580078, 436.94316935539246, 456.0173919200897, 475.4368863105774, 494.2957880496979, 513.1461617946625, 532.5285422801971, 551.4758062362671, 570.3942270278931, 589.4555344581604, 608.6625623703003, 627.9157116413116, 647.3239252567291, 666.4911131858826, 685.4355487823486, 704.472669839859, 723.6665892601013, 742.6218862533569, 761.671347618103, 780.9194157123566, 799.9975099563599, 819.0017716884613, 838.270045042038, 857.3586392402649, 876.0094230175018, 895.5061440467834, 914.5089309215546, 933.4631156921387, 952.8123912811279, 971.7085349559784, 990.6697101593018, 1010.0927493572235, 1029.0930721759796, 1048.4616026878357, 1067.4703664779663, 1086.8416121006012, 1106.2850697040558, 1125.887392282486, 1145.5176146030426, 1164.7743184566498, 1183.9191460609436, 1203.4118831157684, 1222.1416959762573, 1241.2074766159058, 1260.6953663825989, 1279.7688274383545, 1298.6787087917328, 1318.0187950134277, 1337.05770611763, 1355.975425004959, 1375.1012766361237, 1394.0180962085724, 1413.0160994529724, 1432.1844425201416, 1451.2908437252045, 1470.2127239704132, 1489.6127889156342, 1509.1949985027313, 1528.212699174881, 1547.6171402931213, 1567.1605546474457, 1586.3172008991241, 1606.3118245601654, 1626.0931000709534, 1645.0707414150238, 1664.9162430763245, 1684.372090101242, 1703.1889293193817, 1722.0425026416779, 1741.2027502059937, 1760.1069614887238, 1778.8386878967285, 1798.4105608463287, 1817.3866357803345, 1836.2397763729095, 1855.7363619804382, 1874.5571749210358, 1893.458974123001, 1912.4813318252563]