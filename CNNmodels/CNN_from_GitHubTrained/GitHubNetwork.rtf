{\rtf1\ansi\ansicpg1252\cocoartf2757
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 /Users/katebokhan/anaconda3/envs/6.86x/bin/python /Users/katebokhan/Downloads/describable-textures-dataset-classification-main/task_1/train.py\
Using mps device\
\
Epoch 1\
----------------------------------------------\
loss: 3.851130  [    0/11280]\
loss: 3.833918  [ 2560/11280]\
loss: 3.813311  [ 5120/11280]\
loss: 3.809437  [ 7680/11280]\
loss: 3.849419  [10240/11280]\
Training,	Loss: 3.817	| Accuracy: 3.466\
Validation,	Loss: 3.748	| Accuracy: 4.681\
\
Epoch 2\
----------------------------------------------\
loss: 3.769258  [    0/11280]\
loss: 3.799787  [ 2560/11280]\
loss: 3.720469  [ 5120/11280]\
loss: 3.690783  [ 7680/11280]\
loss: 3.762007  [10240/11280]\
Training,	Loss: 3.731	| Accuracy: 5.168\
Validation,	Loss: 3.701	| Accuracy: 5.957\
\
Epoch 3\
----------------------------------------------\
loss: 3.643095  [    0/11280]\
loss: 3.696645  [ 2560/11280]\
loss: 3.733721  [ 5120/11280]\
loss: 3.652109  [ 7680/11280]\
loss: 3.601446  [10240/11280]\
Training,	Loss: 3.681	| Accuracy: 5.771\
Validation,	Loss: 3.735	| Accuracy: 6.489\
\
Epoch 4\
----------------------------------------------\
loss: 3.741171  [    0/11280]\
loss: 3.533794  [ 2560/11280]\
loss: 3.624452  [ 5120/11280]\
loss: 3.549621  [ 7680/11280]\
loss: 3.606005  [10240/11280]\
Training,	Loss: 3.648	| Accuracy: 6.445\
Validation,	Loss: 3.611	| Accuracy: 8.670\
\
Epoch 5\
----------------------------------------------\
loss: 3.615463  [    0/11280]\
loss: 3.535382  [ 2560/11280]\
loss: 3.557508  [ 5120/11280]\
loss: 3.546374  [ 7680/11280]\
loss: 3.517583  [10240/11280]\
Training,	Loss: 3.550	| Accuracy: 8.324\
Validation,	Loss: 3.544	| Accuracy: 8.777\
\
Epoch 6\
----------------------------------------------\
loss: 3.536042  [    0/11280]\
loss: 3.509353  [ 2560/11280]\
loss: 3.459276  [ 5120/11280]\
loss: 3.364423  [ 7680/11280]\
loss: 3.403677  [10240/11280]\
Training,	Loss: 3.434	| Accuracy: 10.780\
Validation,	Loss: 3.350	| Accuracy: 13.191\
\
Epoch 7\
----------------------------------------------\
loss: 3.438055  [    0/11280]\
loss: 3.301181  [ 2560/11280]\
loss: 3.173302  [ 5120/11280]\
loss: 3.327162  [ 7680/11280]\
loss: 3.163204  [10240/11280]\
Training,	Loss: 3.277	| Accuracy: 14.273\
Validation,	Loss: 3.187	| Accuracy: 16.170\
\
Epoch 8\
----------------------------------------------\
loss: 3.153704  [    0/11280]\
loss: 3.262457  [ 2560/11280]\
loss: 2.854509  [ 5120/11280]\
loss: 2.984660  [ 7680/11280]\
loss: 3.036767  [10240/11280]\
Training,	Loss: 3.116	| Accuracy: 17.651\
Validation,	Loss: 3.069	| Accuracy: 19.947\
\
Epoch 9\
----------------------------------------------\
loss: 3.219954  [    0/11280]\
loss: 2.925701  [ 2560/11280]\
loss: 3.154978  [ 5120/11280]\
loss: 2.881591  [ 7680/11280]\
loss: 3.121512  [10240/11280]\
Training,	Loss: 2.945	| Accuracy: 21.206\
Validation,	Loss: 3.048	| Accuracy: 20.904\
\
Epoch 10\
----------------------------------------------\
loss: 2.804781  [    0/11280]\
loss: 2.969466  [ 2560/11280]\
loss: 2.729841  [ 5120/11280]\
loss: 2.996254  [ 7680/11280]\
loss: 2.835880  [10240/11280]\
Training,	Loss: 2.798	| Accuracy: 24.371\
Validation,	Loss: 3.042	| Accuracy: 23.298\
\
Epoch 11\
----------------------------------------------\
loss: 2.672287  [    0/11280]\
loss: 2.903935  [ 2560/11280]\
loss: 2.727356  [ 5120/11280]\
loss: 2.711637  [ 7680/11280]\
loss: 2.633974  [10240/11280]\
Training,	Loss: 2.711	| Accuracy: 25.878\
Validation,	Loss: 2.779	| Accuracy: 27.234\
\
Epoch 12\
----------------------------------------------\
loss: 2.902910  [    0/11280]\
loss: 2.773199  [ 2560/11280]\
loss: 2.697968  [ 5120/11280]\
loss: 2.766053  [ 7680/11280]\
loss: 2.772513  [10240/11280]\
Training,	Loss: 2.593	| Accuracy: 28.759\
Validation,	Loss: 2.692	| Accuracy: 28.404\
\
Epoch 13\
----------------------------------------------\
loss: 2.404406  [    0/11280]\
loss: 2.322216  [ 2560/11280]\
loss: 2.424115  [ 5120/11280]\
loss: 2.495232  [ 7680/11280]\
loss: 2.454148  [10240/11280]\
Training,	Loss: 2.462	| Accuracy: 31.906\
Validation,	Loss: 2.629	| Accuracy: 31.649\
\
Epoch 14\
----------------------------------------------\
loss: 2.373912  [    0/11280]\
loss: 2.694556  [ 2560/11280]\
loss: 2.412324  [ 5120/11280]\
loss: 2.572938  [ 7680/11280]\
loss: 2.548457  [10240/11280]\
Training,	Loss: 2.420	| Accuracy: 33.085\
Validation,	Loss: 2.738	| Accuracy: 30.851\
\
Epoch 15\
----------------------------------------------\
loss: 2.625344  [    0/11280]\
loss: 2.448611  [ 2560/11280]\
loss: 2.218963  [ 5120/11280]\
loss: 2.244069  [ 7680/11280]\
loss: 2.075417  [10240/11280]\
Training,	Loss: 2.313	| Accuracy: 35.151\
Validation,	Loss: 2.585	| Accuracy: 29.521\
\
Epoch 16\
----------------------------------------------\
loss: 2.262932  [    0/11280]\
loss: 1.959692  [ 2560/11280]\
loss: 2.179340  [ 5120/11280]\
loss: 2.250199  [ 7680/11280]\
loss: 2.085234  [10240/11280]\
Training,	Loss: 2.214	| Accuracy: 37.163\
Validation,	Loss: 2.708	| Accuracy: 31.223\
\
Epoch 17\
----------------------------------------------\
loss: 2.162004  [    0/11280]\
loss: 2.065255  [ 2560/11280]\
loss: 2.063996  [ 5120/11280]\
loss: 2.112117  [ 7680/11280]\
loss: 2.124276  [10240/11280]\
Training,	Loss: 2.179	| Accuracy: 39.264\
Validation,	Loss: 2.553	| Accuracy: 32.021\
\
Epoch 18\
----------------------------------------------\
loss: 2.192687  [    0/11280]\
loss: 2.071024  [ 2560/11280]\
loss: 2.051158  [ 5120/11280]\
loss: 2.045485  [ 7680/11280]\
loss: 1.959856  [10240/11280]\
Training,	Loss: 2.096	| Accuracy: 41.817\
Validation,	Loss: 2.505	| Accuracy: 33.245\
\
Epoch 19\
----------------------------------------------\
loss: 1.969504  [    0/11280]\
loss: 2.004210  [ 2560/11280]\
loss: 2.169798  [ 5120/11280]\
loss: 1.868464  [ 7680/11280]\
loss: 1.782463  [10240/11280]\
Training,	Loss: 2.060	| Accuracy: 42.066\
Validation,	Loss: 2.586	| Accuracy: 33.457\
\
Epoch 20\
----------------------------------------------\
loss: 1.976072  [    0/11280]\
loss: 2.377455  [ 2560/11280]\
loss: 2.015027  [ 5120/11280]\
loss: 1.986927  [ 7680/11280]\
loss: 2.187002  [10240/11280]\
Training,	Loss: 2.021	| Accuracy: 43.493\
Validation,	Loss: 2.553	| Accuracy: 35.160\
\
Epoch 21\
----------------------------------------------\
loss: 2.006421  [    0/11280]\
loss: 1.923432  [ 2560/11280]\
loss: 1.895550  [ 5120/11280]\
loss: 2.020399  [ 7680/11280]\
loss: 1.785177  [10240/11280]\
Training,	Loss: 1.979	| Accuracy: 44.433\
Validation,	Loss: 2.645	| Accuracy: 35.319\
\
Epoch 22\
----------------------------------------------\
loss: 1.816584  [    0/11280]\
loss: 2.143488  [ 2560/11280]\
loss: 1.939776  [ 5120/11280]\
loss: 2.109951  [ 7680/11280]\
loss: 1.902933  [10240/11280]\
Training,	Loss: 1.922	| Accuracy: 46.197\
Validation,	Loss: 2.618	| Accuracy: 35.053\
\
Epoch 23\
----------------------------------------------\
loss: 1.880591  [    0/11280]\
loss: 1.961702  [ 2560/11280]\
loss: 1.678462  [ 5120/11280]\
loss: 1.816763  [ 7680/11280]\
loss: 1.666880  [10240/11280]\
Training,	Loss: 1.905	| Accuracy: 46.684\
Validation,	Loss: 2.554	| Accuracy: 35.745\
\
Epoch 24\
----------------------------------------------\
loss: 1.737254  [    0/11280]\
loss: 1.789385  [ 2560/11280]\
loss: 1.864045  [ 5120/11280]\
loss: 1.832362  [ 7680/11280]\
loss: 1.666816  [10240/11280]\
Training,	Loss: 1.827	| Accuracy: 48.910\
Validation,	Loss: 2.424	| Accuracy: 37.713\
\
Epoch 25\
----------------------------------------------\
loss: 1.790599  [    0/11280]\
loss: 1.734660  [ 2560/11280]\
loss: 1.616520  [ 5120/11280]\
loss: 1.885719  [ 7680/11280]\
loss: 1.785107  [10240/11280]\
Training,	Loss: 1.800	| Accuracy: 49.778\
Validation,	Loss: 2.456	| Accuracy: 38.617\
\
Epoch 26\
----------------------------------------------\
loss: 1.734732  [    0/11280]\
loss: 2.053811  [ 2560/11280]\
loss: 1.655311  [ 5120/11280]\
loss: 1.729039  [ 7680/11280]\
loss: 1.662010  [10240/11280]\
Training,	Loss: 1.741	| Accuracy: 50.603\
Validation,	Loss: 2.653	| Accuracy: 36.489\
\
Epoch 27\
----------------------------------------------\
loss: 1.880617  [    0/11280]\
loss: 1.914008  [ 2560/11280]\
loss: 1.759504  [ 5120/11280]\
loss: 2.110583  [ 7680/11280]\
loss: 1.667809  [10240/11280]\
Training,	Loss: 1.731	| Accuracy: 51.649\
Validation,	Loss: 2.601	| Accuracy: 36.170\
\
Epoch 28\
----------------------------------------------\
loss: 1.973787  [    0/11280]\
loss: 1.954720  [ 2560/11280]\
loss: 1.894824  [ 5120/11280]\
loss: 1.979835  [ 7680/11280]\
loss: 1.820106  [10240/11280]\
Training,	Loss: 1.788	| Accuracy: 49.681\
Validation,	Loss: 2.591	| Accuracy: 38.298\
\
Epoch 29\
----------------------------------------------\
loss: 1.747994  [    0/11280]\
loss: 1.333902  [ 2560/11280]\
loss: 1.760032  [ 5120/11280]\
loss: 1.695037  [ 7680/11280]\
loss: 1.715678  [10240/11280]\
Training,	Loss: 1.687	| Accuracy: 52.287\
Validation,	Loss: 2.523	| Accuracy: 36.064\
\
Epoch 30\
----------------------------------------------\
loss: 1.828407  [    0/11280]\
loss: 1.648268  [ 2560/11280]\
loss: 1.822526  [ 5120/11280]\
loss: 1.428576  [ 7680/11280]\
loss: 1.664065  [10240/11280]\
Training,	Loss: 1.671	| Accuracy: 53.342\
Validation,	Loss: 2.499	| Accuracy: 38.191\
\
Epoch 31\
----------------------------------------------\
loss: 1.773904  [    0/11280]\
loss: 1.598766  [ 2560/11280]\
loss: 1.516276  [ 5120/11280]\
loss: 1.482676  [ 7680/11280]\
loss: 1.502282  [10240/11280]\
Training,	Loss: 1.634	| Accuracy: 53.803\
Validation,	Loss: 2.587	| Accuracy: 37.819\
\
Epoch 32\
----------------------------------------------\
loss: 1.506530  [    0/11280]\
loss: 1.607759  [ 2560/11280]\
loss: 1.707446  [ 5120/11280]\
loss: 1.678796  [ 7680/11280]\
loss: 1.513033  [10240/11280]\
Training,	Loss: 1.610	| Accuracy: 54.193\
Validation,	Loss: 2.543	| Accuracy: 37.979\
\
Epoch 33\
----------------------------------------------\
loss: 1.824718  [    0/11280]\
loss: 1.367468  [ 2560/11280]\
loss: 1.590858  [ 5120/11280]\
loss: 1.295803  [ 7680/11280]\
loss: 1.463442  [10240/11280]\
Training,	Loss: 1.603	| Accuracy: 54.566\
Validation,	Loss: 2.699	| Accuracy: 35.585\
\
Epoch 34\
----------------------------------------------\
loss: 1.702125  [    0/11280]\
loss: 1.532833  [ 2560/11280]\
loss: 1.512769  [ 5120/11280]\
loss: 1.585063  [ 7680/11280]\
loss: 1.427665  [10240/11280]\
Training,	Loss: 1.564	| Accuracy: 55.691\
Validation,	Loss: 2.510	| Accuracy: 39.149\
\
Epoch 35\
----------------------------------------------\
loss: 1.417673  [    0/11280]\
loss: 1.607748  [ 2560/11280]\
loss: 1.503811  [ 5120/11280]\
loss: 1.763793  [ 7680/11280]\
loss: 1.710782  [10240/11280]\
Training,	Loss: 1.550	| Accuracy: 56.445\
Validation,	Loss: 2.488	| Accuracy: 40.106\
\
Epoch 36\
----------------------------------------------\
loss: 1.403539  [    0/11280]\
loss: 1.567475  [ 2560/11280]\
loss: 1.650430  [ 5120/11280]\
loss: 1.430058  [ 7680/11280]\
loss: 1.351458  [10240/11280]\
Training,	Loss: 1.547	| Accuracy: 55.904\
Validation,	Loss: 2.511	| Accuracy: 39.681\
\
Epoch 37\
----------------------------------------------\
loss: 1.251494  [    0/11280]\
loss: 1.434556  [ 2560/11280]\
loss: 1.399182  [ 5120/11280]\
loss: 1.821436  [ 7680/11280]\
loss: 1.467619  [10240/11280]\
Training,	Loss: 1.505	| Accuracy: 57.509\
Validation,	Loss: 2.604	| Accuracy: 38.670\
\
Epoch 38\
----------------------------------------------\
loss: 1.477752  [    0/11280]\
loss: 1.826203  [ 2560/11280]\
loss: 1.551582  [ 5120/11280]\
loss: 1.467616  [ 7680/11280]\
loss: 1.552356  [10240/11280]\
Training,	Loss: 1.520	| Accuracy: 56.826\
Validation,	Loss: 2.687	| Accuracy: 38.511\
\
Epoch 39\
----------------------------------------------\
loss: 1.352126  [    0/11280]\
loss: 1.445170  [ 2560/11280]\
loss: 1.612824  [ 5120/11280]\
loss: 1.506136  [ 7680/11280]\
loss: 1.361362  [10240/11280]\
Training,	Loss: 1.478	| Accuracy: 58.129\
Validation,	Loss: 2.578	| Accuracy: 39.574\
\
Epoch 40\
----------------------------------------------\
loss: 1.357228  [    0/11280]\
loss: 1.471999  [ 2560/11280]\
loss: 1.406389  [ 5120/11280]\
loss: 1.374454  [ 7680/11280]\
loss: 1.456979  [10240/11280]\
Training,	Loss: 1.459	| Accuracy: 58.413\
Validation,	Loss: 2.813	| Accuracy: 39.840\
\
Epoch 41\
----------------------------------------------\
loss: 1.508907  [    0/11280]\
loss: 1.326183  [ 2560/11280]\
loss: 1.527866  [ 5120/11280]\
loss: 1.471982  [ 7680/11280]\
loss: 1.394877  [10240/11280]\
Training,	Loss: 1.437	| Accuracy: 58.661\
Validation,	Loss: 2.775	| Accuracy: 37.713\
\
Epoch 42\
----------------------------------------------\
loss: 1.346668  [    0/11280]\
loss: 1.367590  [ 2560/11280]\
loss: 1.685295  [ 5120/11280]\
loss: 1.414061  [ 7680/11280]\
loss: 1.588954  [10240/11280]\
Training,	Loss: 1.447	| Accuracy: 58.387\
Validation,	Loss: 2.649	| Accuracy: 37.660\
\
Epoch 43\
----------------------------------------------\
loss: 1.335776  [    0/11280]\
loss: 1.260045  [ 2560/11280]\
loss: 1.551802  [ 5120/11280]\
loss: 1.387990  [ 7680/11280]\
loss: 1.292434  [10240/11280]\
Training,	Loss: 1.430	| Accuracy: 59.752\
Validation,	Loss: 2.686	| Accuracy: 40.053\
\
Epoch 44\
----------------------------------------------\
loss: 1.222706  [    0/11280]\
loss: 1.511212  [ 2560/11280]\
loss: 1.328016  [ 5120/11280]\
loss: 1.297706  [ 7680/11280]\
loss: 1.247882  [10240/11280]\
Training,	Loss: 1.426	| Accuracy: 59.530\
Validation,	Loss: 2.641	| Accuracy: 38.404\
\
Epoch 45\
----------------------------------------------\
loss: 1.439161  [    0/11280]\
loss: 1.316149  [ 2560/11280]\
loss: 1.531927  [ 5120/11280]\
loss: 1.234344  [ 7680/11280]\
loss: 1.347022  [10240/11280]\
Training,	Loss: 1.403	| Accuracy: 59.761\
Validation,	Loss: 2.551	| Accuracy: 40.160\
\
Epoch 46\
----------------------------------------------\
loss: 1.466811  [    0/11280]\
loss: 1.477630  [ 2560/11280]\
loss: 1.382984  [ 5120/11280]\
loss: 1.535266  [ 7680/11280]\
loss: 1.442489  [10240/11280]\
Training,	Loss: 1.375	| Accuracy: 60.878\
Validation,	Loss: 2.507	| Accuracy: 40.106\
\
Epoch 47\
----------------------------------------------\
loss: 1.439700  [    0/11280]\
loss: 1.509354  [ 2560/11280]\
loss: 1.407866  [ 5120/11280]\
loss: 1.221525  [ 7680/11280]\
loss: 1.524848  [10240/11280]\
Training,	Loss: 1.383	| Accuracy: 60.833\
Validation,	Loss: 2.548	| Accuracy: 41.011\
\
Epoch 48\
----------------------------------------------\
loss: 1.397895  [    0/11280]\
loss: 1.266305  [ 2560/11280]\
loss: 1.549080  [ 5120/11280]\
loss: 1.265847  [ 7680/11280]\
loss: 1.506730  [10240/11280]\
Training,	Loss: 1.390	| Accuracy: 61.232\
Validation,	Loss: 2.567	| Accuracy: 40.745\
\
Epoch 49\
----------------------------------------------\
loss: 1.179505  [    0/11280]\
loss: 1.309392  [ 2560/11280]\
loss: 1.231634  [ 5120/11280]\
loss: 1.424159  [ 7680/11280]\
loss: 1.561409  [10240/11280]\
Training,	Loss: 1.366	| Accuracy: 61.294\
Validation,	Loss: 2.700	| Accuracy: 40.160\
\
Epoch 50\
----------------------------------------------\
loss: 1.347581  [    0/11280]\
loss: 1.377224  [ 2560/11280]\
loss: 1.571365  [ 5120/11280]\
loss: 1.441029  [ 7680/11280]\
loss: 1.640783  [10240/11280]\
Training,	Loss: 1.384	| Accuracy: 60.727\
Validation,	Loss: 2.646	| Accuracy: 40.904\
Time usage: 8:15:30\
Finished Training\
Using mps device\
Traceback (most recent call last):\
  File "/Users/katebokhan/Downloads/describable-textures-dataset-classification-main/task_1/train.py", line 90, in <module>\
    kernels, feature_maps, input_img = util.visualize_kernels_and_feature_maps()\
  File "/Users/katebokhan/Downloads/describable-textures-dataset-classification-main/task_1/util.py", line 167, in visualize_kernels_and_feature_maps\
    model.load_state_dict(torch.load(path))\
  File "/Users/katebokhan/anaconda3/envs/6.86x/lib/python3.8/site-packages/torch/serialization.py", line 809, in load\
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\
  File "/Users/katebokhan/anaconda3/envs/6.86x/lib/python3.8/site-packages/torch/serialization.py", line 1172, in _load\
    result = unpickler.load()\
  File "/Users/katebokhan/anaconda3/envs/6.86x/lib/python3.8/site-packages/torch/serialization.py", line 1142, in persistent_load\
    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\
  File "/Users/katebokhan/anaconda3/envs/6.86x/lib/python3.8/site-packages/torch/serialization.py", line 1116, in load_tensor\
    wrap_storage=restore_location(storage, location),\
  File "/Users/katebokhan/anaconda3/envs/6.86x/lib/python3.8/site-packages/torch/serialization.py", line 217, in default_restore_location\
    result = fn(storage, location)\
  File "/Users/katebokhan/anaconda3/envs/6.86x/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize\
    device = validate_cuda_device(location)\
  File "/Users/katebokhan/anaconda3/envs/6.86x/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device\
    raise RuntimeError('Attempting to deserialize object on a CUDA '\
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\
\
Process finished with exit code 1\
}